{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenreClassification_BERT_Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM32PHMu1DprK/Dh+BB41nS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stone-bridge-NLP/BERT/blob/main/GenreClassification_BERT_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zKanZlPVCBy"
      },
      "source": [
        "# Demo of Genre Classification using BERT embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZHTYDdCSbNl"
      },
      "source": [
        "Hongik univ 2021 NLP team project  \n",
        "JunHyeon Kwon\n",
        "\n",
        "Huggingface usage referenced from here:  \n",
        "https://colab.research.google.com/github/pytorch/pytorch.github.io/blob/master/assets/hub/huggingface_pytorch-transformers.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5shtAgqVZEb"
      },
      "source": [
        "# Setting Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySPqjCY-SFej",
        "outputId": "e440cfac-7193-425e-e584-7cb14de0d10f"
      },
      "source": [
        "# required packages to use BERT via hub models\n",
        "%%bash\n",
        "pip install tqdm boto3 requests regex sentencepiece sacremoses"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.20.19-py3-none-any.whl (131 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "Collecting botocore<1.24.0,>=1.23.19\n",
            "  Downloading botocore-1.23.19-py3-none-any.whl (8.4 MB)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.19->boto3) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.19->boto3) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.20.19 botocore-1.23.19 jmespath-0.10.0 s3transfer-0.5.0 sacremoses-0.0.46 sentencepiece-0.1.96 urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSFVDUlHVpXP",
        "outputId": "858238e8-b579-489e-c54e-d36093852ee5"
      },
      "source": [
        "# additional packages required (to avoid error, not mentioned in the tutorial)\n",
        "!pip install huggingface_hub\n",
        "!pip install tokenizers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▎                          | 10 kB 22.8 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 20 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 30 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 40 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 51 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 61 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61 kB 451 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.10.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.8.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface_hub) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface_hub) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub) (2021.10.8)\n",
            "Installing collected packages: huggingface-hub\n",
            "Successfully installed huggingface-hub-0.2.1\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 7.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9YdDM-9VtqY",
        "outputId": "0a3c6dd1-105b-440c-f6cd-0d8e00a9bff8"
      },
      "source": [
        "# clone my github repo to import utils.py\n",
        "!git clone https://github.com/Stone-bridge-NLP/BERT.git\n",
        "%cp /content/BERT/utils.py /content/utils.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BERT'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 56 (delta 17), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (56/56), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0a6dvLeWVV0",
        "outputId": "d193bad2-94c7-4224-c07c-a7c0c087b0e2"
      },
      "source": [
        "# download model save and dataset to local disk\n",
        "\n",
        "# https://drive.google.com/file/d/1PWrQeJ7bu1OAufGshDBO8e3qdtUy35xA/view?usp=sharing\n",
        "!gdown --id 1PWrQeJ7bu1OAufGshDBO8e3qdtUy35xA\n",
        "SAVE_FILENAME = 'checkpoint.pth'\n",
        "# https://drive.google.com/file/d/168qGvi5w4Wwgu5QTpPoLkZzoJNAgyc6b/view?usp=sharing\n",
        "!gdown --id 168qGvi5w4Wwgu5QTpPoLkZzoJNAgyc6b\n",
        "TEST_FILENAME = 'preprocessed_test_data.csv'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PWrQeJ7bu1OAufGshDBO8e3qdtUy35xA\n",
            "To: /content/checkpoint.pth\n",
            "100% 27.8M/27.8M [00:00<00:00, 170MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=168qGvi5w4Wwgu5QTpPoLkZzoJNAgyc6b\n",
            "To: /content/preprocessed_test_data.csv\n",
            "100% 9.63M/9.63M [00:00<00:00, 85.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEtQk1HEXYZT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import utils"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R87l_5D4kATn"
      },
      "source": [
        "# Define model and other classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAu6J2v4YHc1"
      },
      "source": [
        "# Custom class from torch.utils.data.Dataset\n",
        "# Tokenization and integer labeling happens here\n",
        "# shuffle and batch tokenizing can be done with torch.utils.data.DataLoader\n",
        "class LyricsAndGenreDataset(Dataset):\n",
        "  def __init__(self, dataframe, tokenizer, num_sentence):\n",
        "    self.df = dataframe\n",
        "    self.tk = tokenizer\n",
        "    self.num_sentence = num_sentence\n",
        "    self.genre_name2id = {\n",
        "        'Electronic':0, \n",
        "        'Country':1, \n",
        "        'R&B':2, \n",
        "        'Jazz':3, \n",
        "        'Indie':4, \n",
        "        'Pop':5, \n",
        "        'Folk':6, \n",
        "        'Metal':7, \n",
        "        'Hip-Hop':8, \n",
        "        'Rock':9}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "\n",
        "    genre = self.genre_name2id[self.df['Genre'][idx]]\n",
        "    lyric = [self.df['Lyrics'][idx]]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      indexed_tokens = self.tk.batch_encode_plus(\n",
        "            lyric, add_special_tokens=True, padding= 'max_length', \n",
        "            max_length=2**9*self.num_sentence, truncation=True)\n",
        "      \n",
        "      tk_tensor = torch.tensor(indexed_tokens['input_ids']).view(-1,2**9)\n",
        "      sg_tensor = torch.tensor(indexed_tokens['token_type_ids']).view(-1,2**9)\n",
        "      at_tensor = torch.tensor(indexed_tokens['attention_mask']).view(-1,2**9)\n",
        "\n",
        "    return genre, tk_tensor, sg_tensor, at_tensor"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TiLz8xQYJsI"
      },
      "source": [
        "# classifier model\n",
        "# manually stacked lstm layer to gradually decrease hidden_size\n",
        "# one FC layer attached at the end\n",
        "# ====================================\n",
        "# Param seq_len has the sequence length info of each song in a batch.\n",
        "# For some songs, sequence ends way earlier than 512 tokens, resulting \n",
        "# long sequence of padding at the end. This might make it hard for lstm\n",
        "# to extract useful information from the sequence. With the info from seq_len\n",
        "# it pulls output from certain time step and feeds to the FC layer.\n",
        "class TextLSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, n_class):\n",
        "    super(TextLSTM, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.lstm1 = nn.LSTM(\n",
        "              input_size=input_size,\n",
        "              hidden_size=hidden_size*5,\n",
        "              num_layers=1,\n",
        "              dropout=0,\n",
        "              batch_first=True)\n",
        "    \n",
        "    self.lstm2 = nn.LSTM(\n",
        "              input_size=hidden_size*5,\n",
        "              hidden_size=hidden_size*4,\n",
        "              num_layers=1,\n",
        "              dropout=0,\n",
        "              batch_first=True)\n",
        "\n",
        "    self.lstm3 = nn.LSTM(\n",
        "              input_size=hidden_size*4,\n",
        "              hidden_size=hidden_size*2,\n",
        "              num_layers=1,\n",
        "              dropout=0,\n",
        "              batch_first=True)\n",
        "    \n",
        "    self.lstm4 = nn.LSTM(\n",
        "              input_size=hidden_size*2,\n",
        "              hidden_size=hidden_size,\n",
        "              num_layers=1,\n",
        "              dropout=0,\n",
        "              batch_first=True)\n",
        "\n",
        "    self.dense = nn.Sequential(\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_size, n_class),\n",
        "        nn.Softmax(dim=1))\n",
        "\n",
        "  def forward(self, X, seq_len):\n",
        "    # X of shape N,L,Hin\n",
        "    # hidden_and_cell zeros by default\n",
        "    # outputs of shape N,L,Hout\n",
        "    outputs = X\n",
        "    outputs, hidden_and_cell = self.lstm1(outputs)\n",
        "    outputs, hidden_and_cell = self.lstm2(outputs)\n",
        "    outputs, hidden_and_cell = self.lstm3(outputs)\n",
        "    outputs, hidden_and_cell = self.lstm4(outputs)\n",
        "    seq_len = torch.tile(seq_len.view(batch_size,1,1),(1,1,self.hidden_size))\n",
        "    outputs = torch.gather(outputs,1,seq_len)\n",
        "    outputs = outputs[:,-1]  # last hidden Layer of shape N,Hout\n",
        "    return self.dense(outputs) # return of shape N,n_class"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9toF6JmAkScc"
      },
      "source": [
        "# Load and Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5e37oxyYZNQ"
      },
      "source": [
        "#### hyperparameters ####\n",
        "batch_size = 128\n",
        "\n",
        "# fixed parameters\n",
        "hidden_size = 128\n",
        "num_sentences = 1\n",
        "v_dim = 768\n",
        "n_genre = 10\n",
        "genre_id2name = ['Electronic', 'Country', 'R&B', 'Jazz', 'Indie', 'Pop', 'Folk', 'Metal', 'Hip-Hop', 'Rock']\n",
        "genre_name2id = {'Electronic':0, 'Country':1, 'R&B':2, 'Jazz':3, 'Indie':4, 'Pop':5, 'Folk':6, 'Metal':7, 'Hip-Hop':8, 'Rock':9}\n",
        "device = torch.device('cuda') if (torch.cuda.is_available())else torch.device('cpu')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPFNnna8YRb1",
        "outputId": "b2eb411b-5994-4101-a751-f38bdfaad8ce"
      },
      "source": [
        "## load the dataset and model save\n",
        "\n",
        "# load pretrained BERT tokenizer and bare BERT model\n",
        "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-cased')\n",
        "bert_embedding = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-cased').to(device)\n",
        "\n",
        "# load test dataset\n",
        "test_dataset = pd.read_csv('./'+TEST_FILENAME)\n",
        "print(test_dataset['Genre'].value_counts())\n",
        "print(len(test_dataset))\n",
        "\n",
        "# declare torch.utils.data.Dataset\n",
        "test_set = LyricsAndGenreDataset(test_dataset,tokenizer,num_sentences)\n",
        "\n",
        "# test data loader\n",
        "test_loader = DataLoader(test_set,batch_size=batch_size, shuffle=True, \n",
        "                          num_workers=0, drop_last=True)\n",
        "\n",
        "# model\n",
        "lstm_classifier = TextLSTM(v_dim, hidden_size, n_genre).to(device)\n",
        "\n",
        "# load model if possible\n",
        "try:\n",
        "  cp = torch.load(SAVE_FILENAME)\n",
        "  epoch_start= cp['current_epoch']+1\n",
        "  lstm_classifier.load_state_dict(cp['model'])\n",
        "  print(f'\\nsavefile from {SAVE_FILENAME} loaded')\n",
        "except FileNotFoundError:\n",
        "  print(f'\\nNo such savefile {SAVE_FILENAME}')\n",
        "\n",
        "# print summary\n",
        "print(lstm_classifier)\n",
        "print(sum(p.numel() for p in lstm_classifier.parameters() if p.requires_grad))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n",
            "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rock          1410\n",
            "Pop           1110\n",
            "Hip-Hop        960\n",
            "Country        810\n",
            "Metal          810\n",
            "Electronic     659\n",
            "Jazz           659\n",
            "Indie          510\n",
            "R&B            509\n",
            "Folk           495\n",
            "Name: Genre, dtype: int64\n",
            "7932\n",
            "\n",
            "savefile from checkpoint.pth loaded\n",
            "TextLSTM(\n",
            "  (lstm1): LSTM(768, 640, batch_first=True)\n",
            "  (lstm2): LSTM(640, 512, batch_first=True)\n",
            "  (lstm3): LSTM(512, 256, batch_first=True)\n",
            "  (lstm4): LSTM(256, 128, batch_first=True)\n",
            "  (dense): Sequential(\n",
            "    (0): ReLU()\n",
            "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
            "    (2): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "6960394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dXN88BvZULZ",
        "outputId": "677aea08-702c-4e7d-ef22-ae905092a4df"
      },
      "source": [
        "# test the model with test dataset\n",
        "lstm_classifier.eval()\n",
        "c_mat = np.zeros((10,4)) # confusion matrix. TP, FP, FN, TN\n",
        "f1 = []\n",
        "with torch.no_grad():\n",
        "  for b, batch in enumerate(test_loader):\n",
        "    label_batch = batch[0].to(device)\n",
        "    tk_batch = batch[1].to(device)\n",
        "    sg_batch = batch[2].to(device)\n",
        "    at_batch = batch[3].to(device)\n",
        "\n",
        "    seq_len = np.sum(at_batch.detach().cpu().numpy(), axis=(1,2)) - 1\n",
        "    seq_len = torch.LongTensor(seq_len).to(device)\n",
        "\n",
        "    embedding = bert_embedding(\n",
        "        tk_batch.view(-1,2**9), \n",
        "        token_type_ids= sg_batch.view(-1,2**9),\n",
        "        attention_mask=at_batch.view(-1,2**9))\n",
        "\n",
        "    embedded_tokens = embedding[0].view(batch_size,2**9*num_sentences,-1)\n",
        "\n",
        "    output = lstm_classifier.forward(embedded_tokens, seq_len)\n",
        "    \n",
        "    pred = torch.argmax(output,axis=1)\n",
        "\n",
        "    acc = float(torch.sum(pred == label_batch))/batch_size\n",
        "    print(f'\\rbatch [{b}/{len(test_loader)}] acc: {acc}', end='\\t')\n",
        "\n",
        "    # build confusion matrix\n",
        "    for i in range(10):\n",
        "      c_mat[i,0] += int(torch.sum((pred == i)*(label_batch == i)))\n",
        "      c_mat[i,1] += int(torch.sum((pred == i)*(label_batch != i)))\n",
        "      c_mat[i,2] += int(torch.sum((pred != i)*(label_batch == i)))\n",
        "      c_mat[i,3] += int(torch.sum((pred != i)*(label_batch != i)))\n",
        "\n",
        "\n",
        "# calculate precision, recall and f1-score\n",
        "precision = [c[0]/(c[0]+c[1]) if c[0] != 0 else 0 for c in c_mat]\n",
        "recall = [c[0]/(c[0]+c[2]) if c[0] != 0 else 0 for c in c_mat]\n",
        "f1 = [2*p*r/(p+r) if p*r != 0 else 0 for p, r in zip(precision,recall)]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch [60/61] acc: 0.359375\t"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CdooUfnkbgZ"
      },
      "source": [
        "# Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fATE9EsBZYNp",
        "outputId": "146643d3-a97d-424b-f4e6-32e9cdc1cc44"
      },
      "source": [
        "# show confusion matrix\n",
        "print('confusion matrix. TP, FP, FN, TN')\n",
        "for g, c in zip(genre_id2name,c_mat):\n",
        "  print('%-15s'%(g), c)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix. TP, FP, FN, TN\n",
            "Electronic      [ 171.  764.  480. 6393.]\n",
            "Country         [ 253.  401.  543. 6611.]\n",
            "R&B             [ 113.  550.  386. 6759.]\n",
            "Jazz            [ 278.  829.  373. 6328.]\n",
            "Indie           [ 132.  804.  370. 6502.]\n",
            "Pop             [ 111.  232.  987. 6478.]\n",
            "Folk            [ 194.  698.  291. 6625.]\n",
            "Metal           [ 580.  673.  213. 6342.]\n",
            "Hip-Hop         [ 723.  154.  216. 6715.]\n",
            "Rock            [  36.  112. 1358. 6302.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZV95KuAZaW4",
        "outputId": "1722c3e9-e69d-47b6-8402-386366f68252"
      },
      "source": [
        "# compare f1 score with random prediction\n",
        "test_dataset = pd.read_csv('./'+TEST_FILENAME)\n",
        "\n",
        "P = [n/len(test_dataset) for n in test_dataset['Genre'].value_counts()]\n",
        "f1_score = {n:2*p*0.5/(0.5+p) for n, p in zip(test_dataset['Genre'].value_counts().index, P)}\n",
        "print('%-15s %11s   %11s'%('Genre', 'f1 test', 'f1 at least'))\n",
        "for i, g in enumerate(genre_id2name):\n",
        "  print('%-15s %-2.9f   %-2.9f'%(g, f1[i], f1_score[g]))\n",
        "\n",
        "print('-'*43)\n",
        "print('%-15s %-2.9f   %-2.9f'%('average',np.mean(f1),sum(f1_score.values())/10))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Genre               f1 test   f1 at least\n",
            "Electronic      0.215636822   0.142486486\n",
            "Country         0.348965517   0.169597990\n",
            "R&B             0.194492255   0.113743017\n",
            "Jazz            0.316268487   0.142486486\n",
            "Indie           0.183588317   0.113941019\n",
            "Pop             0.154059681   0.218676123\n",
            "Folk            0.281771968   0.110961668\n",
            "Metal           0.566959922   0.169597990\n",
            "Hip-Hop         0.796255507   0.194884287\n",
            "Rock            0.046692607   0.262276786\n",
            "-------------------------------------------\n",
            "average         0.310469108   0.163865185\n"
          ]
        }
      ]
    }
  ]
}